## Введение

### Основные вопросы:

✅ Что такое Docker?  
✅ Чем контейнер отличается от виртуальной машины?  
✅ Почему контейнеризация стала стандартом в разработке?

### Что такое докер?
Docker — это платформа для контейнеризации, которая позволяет разработчикам упаковывать приложения и их зависимости в контейнеры — изолированные среды, включающие код, библиотеки, настройки и системные инструменты. Контейнеры обеспечивают портативность, позволяя приложению запускаться одинаково на любом устройстве с установленным Docker, будь то локальный компьютер, сервер или облачная инфраструктура.

Контейнеры используют ядро хоста (например, Linux или Windows), что делает их лёгкими и быстрыми в сравнении с виртуальными машинами. Docker предоставляет инструменты для создания образов (Dockerfile), управления контейнерами (docker run, docker stop) и их оркестрации (Docker Compose, Docker Swarm).

Пример: разработчик может написать Dockerfile для веб-приложения, собрать образ с помощью docker build и запустить его на любом сервере с Docker Engine, не беспокоясь о различиях в версиях Python, библиотек или системных зависимостей.
#### Почему контейнеризация стала стандартом?

Контейнеризация популярна благодаря портативности: приложение работает одинаково везде, от разработчика до продакшна. Она экономит ресурсы, ускоряет развертывание и идеально подходит для облачных технологий, таких как Kubernetes. Это особенно важно для современных микросервисных архитектур, где скорость и масштабируемость критичны.
#### Чем контейнер отличается от виртуальной машины?

Контейнеры и виртуальные машины (ВМ) — это технологии виртуализации, но они работают на разных уровнях.

- **Контейнеры:** Это изолированные процессы, которые используют ядро хоста. Они включают только приложение и его зависимости, такие как библиотеки и настройки, но не содержат отдельной операционной системы. Это делает их лёгкими (обычно несколько мегабайт) и быстрыми в запуске (секунды). Контейнеры используют технологии ядра Linux, такие как пространства имен (namespaces) и группы управления (cgroups), для изоляции и ограничения ресурсов.
- **Виртуальные машины:** Это эмуляция полной компьютерной системы, включая аппаратное обеспечение и операционную систему. Каждая ВМ имеет собственное ядро и ОС (например, Windows, Linux), что обеспечивает сильную изоляцию, но требует больше ресурсов (обычно гигабайты) и времени на запуск (минуты). ВМ работают на гипервизоре (например, VMware, Hyper-V, VirtualBox), который управляет распределением ресурсов хоста между гостевыми машинами.
**Таблица сравнения:**

| Характеристика   | Контейнеры          | Виртуальные машины |
| ---------------- | ------------------- | ------------------ |
| Ядро             | Общее с хостом      | Собственное        |
| Размер           | МБ                  | ГБ                 |
| Скорость запуска | Секунды             | Минуты             |
| Изоляция         | namespaces, cgroups | Гипервизор         |

---
## Как? 

### Docker componentes
**Основные компоненты Docker:**

- **Docker Host**: Операционная система, на которой установлен Docker и работает демон.
- **Docker Daemon (dockerd)**: Служба, управляющая объектами Docker и обеспечивающая их работу.
- **Docker Client (docker)**: Консольный клиент, через который пользователи взаимодействуют с демоном Docker, отправляя команды для создания и управления контейнерами.
- **Docker Image**: Неизменяемый образ, из которого запускаются контейнеры.
- **Docker Container**: Запущенный экземпляр образа, представляющий собой изолированное приложение.
- **Docker Registry**: Репозиторий для хранения и распространения Docker-образов.
- **Dockerfile**: Файл с инструкциями для сборки Docker-образа.
- **Docker Compose**: Инструмент для управления многоконтейнерными приложениями, позволяющий описывать их конфигурацию в YAML-файле.



### read dockerfile?
#### Процесс сборки образа из Dockerfile

1. **Чтение Dockerfile:**  
    Команда docker build читает Dockerfile, который содержит инструкции, такие как FROM, ADD, COPY, RUN, EXPOSE и другие. Эти инструкции определяют, как будет построен образ. Например, инструкция FROM указывает базовый образ, с которого начинается процесс.
2. **Создание слоёв:**  
    Каждая инструкция в Dockerfile создаёт новый слой в образе. Слои представляют собой снимки файловой системы на разных этапах сборки.
    - Инструкция FROM задаёт базовый образ, который становится первым слоем.
    - ADD или COPY добавляют файлы в файловую систему образа, создавая новый слой.
    - RUN выполняет команду в временном контейнере, созданном из текущего состояния образа, и фиксирует изменения как новый слой. Например, команда RUN apt-get update && apt-get install -y some_package устанавливает пакет и сохраняет изменения.
    - Инструкции, такие как EXPOSE, не создают слои, а добавляют метаданные, например, указывая порты, которые контейнер будет слушать.
3. **Использование временных контейнеров:**  
    Во время выполнения инструкции RUN Docker создаёт временный контейнер из текущего состояния образа, выполняет команду внутри него и фиксирует изменения как новый слой. Это важно, так как позволяет изолировать выполнение команд и управлять зависимостями. Например, установка пакета через apt-get происходит в изолированной среде, что предотвращает влияние на хост-систему.
4. **Кэширование для ускорения:**  
    Docker использует механизм кэширования для ускорения сборки. Если слой не изменился с последнего построения (например, файл, добавленный через COPY, остался прежним), Docker может использовать существующий слой, вместо того чтобы пересоздавать его. Это особенно полезно для больших образов, где повторные сборки могут быть долгими.
5. **Хранение слоёв:**  
    Слои хранятся в системе с доступом по содержимому, где каждый слой идентифицируется хэшем его содержимого. Это позволяет эффективно управлять пространством и избегать дублирования данных. Например, если два образа используют один и тот же базовый слой, он не дублируется, а используется совместно.
6. **Объединённая файловая система:**  
    Для комбинирования слоёв используется объединённая файловая система, такая как AUFS или overlayFS. Эти технологии позволяют наложить несколько слоёв в единое представление файловой системы, где верхние слои могут перекрывать нижние. Это критично для работы Docker, так как позволяет создавать лёгкие и модульные образы.
**Пример Dockerfile:**

```dockerfile
FROM python:3.9
RUN pip install flask
COPY app.py /app/
CMD ["python", "/app/app.py"]
```

### docker run?
#### Процесс запуска контейнера

1. **Создание контейнера:**  
    Когда выполняется команда docker run, Docker создаёт новый экземпляр контейнера на основе указанного образа. Контейнер — это запущенный экземпляр образа, который имеет собственное пространство процессов, сеть и файловую систему.
2. **Настройка пространств имен (Namespaces):**  
    Для изоляции контейнера от хоста используются пространства имен ядра Linux. Это включает:
    - **PID namespace:** Изолирует идентификаторы процессов, так что процессы внутри контейнера имеют собственное пространство PID.
    - **Network namespace:** Создаёт изолированную сеть, где контейнер имеет собственные интерфейсы и IP-адреса. По умолчанию используется мостовая сеть (bridge network), позволяющая общаться с другими контейнерами и хостом.
    - **Mount namespace:** Изолирует файловую систему, предоставляя контейнеру собственное представление файлов.
3. **Настройка групп управления (Cgroups):**  
    Группы управления используются для ограничения и мониторинга использования ресурсов контейнером, таких как CPU, память и ввод-вывод. Это позволяет предотвращать перегрузку хоста и управлять производительностью.
4. **Монтирование файловой системы:**  
    Файловая система контейнера формируется как объединение слоёв образа (читаемых) и нового записываемого слоя для контейнера. Объединённая файловая система, например overlayFS, позволяет комбинировать слои так, что изменения, сделанные в контейнере, записываются только в верхний слой, не затрагивая нижние. Это обеспечивает эффективность, так как несколько контейнеров могут делить одни и те же слои образа.
5. **Запуск основного процесса:**  
    Основной процесс, указанный в образе через инструкцию CMD или ENTRYPOINT в Dockerfile, запускается в пространстве имен контейнера. Например, если в образе указано CMD ["nginx", "-g", "daemon off;"], то при запуске контейнера будет запущен веб-сервер Nginx.
6. **Управление жизненным циклом контейнера:**  
    Контейнер работает, пока не завершится основной процесс, если не указано иное (например, с флагом -d для работы в отрытом режиме). При завершении процесса контейнер останавливается, но его данные в записываемом слое сохраняются, если контейнер не удалён.
### namespaces
Я не буду сильно прям углубляться, потому что про namespace можно говорить очень много и очень долго.
Скорее, мы просто посмотрим на него, окунем ножки и с словами «с меня хватит» перейдем к другому :)
[Linux namespace](http://man7.org/linux/man-pages/man7/namespaces.7.html) – это абстракция над ресурсами в операционной системе. Мы можем думать об namespace, как о ящике. В этом ящике находятся системные ресурсы, которые точно зависят от типа ящика (namespace). В настоящее время существует семь типов пространств имён (namespaces): Cgroups, IPC, Network, Mount, PID, User, UTS.

Например, Network namespace включает в себя системные ресурсы, связанные с сетью, такие как сетевые интерфейсы (например, `wlan0`, `eth0`), таблицы маршрутизации и т.д., Mount namespace включает файлы и каталоги в системе, PID содержит ID процессов и так далее. Таким образом, два экземпляра Network namespace **A** и **B** (соответствующие двум ящикам одного типа в нашей аналогии) могут содержать различные ресурсы – возможно, **A** содержит `wlan0`, тогда как **B** содержит `eth0` и отдельную копию таблицы маршрутизации.

Пространства имён (namespaces) – не какая-то дополнительная фича или библиотека, которую вам нужно установить, например, с помощью пакетного менеджера apt. Они предоставляются самим ядром Linux и уже являются необходимостью для запуска любого процесса в системе. В любой данный момент времени любой процесс **P** принадлежит ровно одному экземпляру namespace каждого типа. Поэтому, когда ему требуется сказать «обнови таблицу маршрутизации в системе», Linux показывает ему копию таблицы маршрутизации namespace, к которому он принадлежит в этот момент.
Процесс в Linux всегда должен принадлежать к какому нибудь пространству имен. Иначе никак.
Команда `unshare` запускает программу (опционально) в новом namespace. Флаг `-u` говорит ей запустить `bash` в новом UTS namespace. Обратите внимание, что наш новый процесс `bash` указывает на другой файл `uts`, тогда как все остальные остаются прежними.
Одним из следствий того, что мы только что проделали, является то, что теперь мы можем изменить системный hostname из нашего нового процесса bash и это не повлияет ни на какой другой процесс в системе. Вы можете проверить это, выполнив `hostname` в первом терминале и увидев, что имя хоста там не изменилось.

Надеюсь, теперь у вас есть некоторое представление о том, что может делать namespace. Вы можете предположить, что контейнеры по своей сути — обыкновенные процессы с отличающимися от других процессов namespaces, и вы будете правы. Фактически это квота. Контейнер без квот не обязан принадлежать уникальному namespace каждого типа — он может совместно использовать некоторые из них.

Кстати, мы можем указать докеру, чтоб он использовал что то с хост неймспейса. Например, docker run --net=host redis.
Мы говорим, слушай, докер, не создавай нетворк неймспейс для редиски.
И с точки зрения сети, редиска будет такая же как и все. 
И такое можно провернуть не только для сети.
Тут возникает вопрос, что же такое контейнер? Остаётся ли контейнером процесс, использующий все, кроме одного, общие namespace? Обычно контейнеры идут вместе с понятием **изоляции**, достигаемой через namespaces: чем меньше количество namespaces и ресурсов, которые процесс делит с остальными, тем более он изолирован и это всё, что действительно имеет значение. 
Паста про бабочку :)

### А теперь, мы идем к cgroup)))909))

Ну вообще, сигруп нужен для ограничения и мониторинга использования процессора, памяти и др.
Cgroups — это механизм ядра Linux, который позволяет ограничивать, учитывать и изолировать использование системных ресурсов для групп процессов. Допустим, мы хотим ограничить потребление яги. Cgroups делают то же самое, только вместо яги — CPU, память, диск и другие ресурсы.

**Основные контроллеры cgroups:**

- **CPU**: конролирует использование процессорного времени. Можно установить лимиты на процент использования CPU или распределять время между группами процессов.
    
- **Memory**: ограничивает использование оперативной памяти и swap.
    
- **IO**: контролирует ввод-вывод на блочные устройства.
    
- **Devices**: управляет доступом к устройствам. Позволяет разрешить или запретить определённым процессам доступ к конкретным устройствам.
    
- **PIDs**: ограничивает количество процессов в группе.
    

Стоит отметить, что существует две версии cgroups: **v1** и **v2**. Вторая версия объединяет все контроллеры в единую иерархию и упрощает управление. В современных дистрибутивах Linux по дефолту используется cgroups v2.

Cgroups используют псевдофайловую систему, которая монтируется в `/sys/fs/cgroup/`.

### runc
runC - это инструмент CLI для создания и запуска контейнеров в соответствии со спецификацией OCI. Он был выпущен Docker container platform в 2015 году в рамках разработки компонентов planning. Как указано в анонсе:

runC - это легкая, портативная среда выполнения контейнеров. Он включает в себя весь программный код, используемый Docker для взаимодействия с системными функциями, связанными с контейнерами. 
Главные фичи:
Полная поддержка пространств имен Linux
Встроенная поддержка функций безопасности Linux, таких как Selinux, Apparmor
Спецификации регулируются Open Container Initiative — частью Linux Foundation.

### contrainerd & containerd-shim
[containerd](https://containerd.io/) — это бывшая часть Docker, а ныне самостоятельное решение, реализующее **исполняемую среду для запуска контейнеров**. При его создании, как утверждают разработчики, они стремились к простоте, надёжности и портируемости.  
  
«Физически» это демон на хост-системе, который управляет всем жизненным циклом контейнера: от получения и хранения образа до запуска контейнера _(через **runC** — подробнее см. ниже)_ и контролирования его работы. С демоном containerd можно взаимодействовать по низкоуровневому **gRPC API** через локальный UNIX-сокет, а для экспериментов и отладки также доступна консольная утилита **ctr** _(она тоже использует gRPC API)_. Исходный код написан на Go и доступен на [GitHub](https://github.com/docker/containerd) под лицензией Apache License 2.0.
Основные примитивы, с которыми работает containerd, — это **bundles** _(«комплекты»)_ и контейнеры. Запуском контейнеров занимается [runC](http://runc.io/) — утилита, написанная на Go, использующая libcontainer и [отделённая](https://blog.docker.com/2015/06/runc/) от Docker в 2015 году. Она работает в соответствии со спецификацией [OCI Runtime Specification](https://github.com/opencontainers/runtime-spec) и запускает контейнеры как свои дочерние процессы. Для запуска требует только корневую файловую систему и конфигурацию _(всё остальное: получение образа, его распаковка и т.п. — остаётся для неё «за кадром»)_.  
  
Bundles содержат конфигурацию, метаданные и данные корневой файловой системы. Они являются дисковым представлением запущенного контейнера _(в простейшем случае — это обычный каталог в ФС)_, которое можно переносить на другие системы, упаковывать и распространять. **По сути всё устройство containerd заключается в том, чтобы координировать создание и запуск bundles.**
Набор функций, выполнение которых поручили containerd, получился следующим:  
- размещение образов в Docker Registry;
- поддержка сети для создания системных интерфейсов и API для управления сетевым пространством имён контейнера;
- хранилище (на уровне хоста) для файловых систем образа и контейнера;
- gRPC API (именно по нему и сам Docker Engine общается с containerd);
- новый API для метрик в формате Prometheus, используемых внутри и на уровне контейнера;
- полная поддержка спецификации образов OCI (Open Container Initiative) и эталонной реализации runC.
Ну есть еще контейнерди шим, который в свою очередь буквально прослойка для метрик и т.п. и обращается к runc.
**Пример:** ` ctr container run docker.io/library/alpine:latest myalp sh`

---
## Как Docker управляет файлами и образами? 

### Основные темы:

✅ Что такое UnionFS и OverlayFS?  
✅ Как Docker хранит образы и почему важны слои?  
✅ Как работает кеширование `docker build`?

### UnionFS
Каскадно-объединённое монтирование — это тип файловой системы, в которой создается иллюзия объединения содержимого нескольких каталогов в один без изменения исходных (физических) источников. Такой подход может оказаться полезным, если имеются связанные наборы файлов, хранящиеся в разных местах или на разных носителях, но отображать их надо как единое и совокупное целое. Например, набор пользовательских/корневых каталогов, расположенных на удалённых NFS-серверах, можно свести в один каталог или можно объединить разбитый на части ISO-образ в один целый образ.
Объединённая файловая система также обеспечивает изоляцию, поскольку контейнеры имеют доступ к общим слоям образа только для чтения. Если контейнерам когда-нибудь понадобится внести изменения в любой файл, доступный только для чтения, они используют стратегию копирования при записи copy-on-write (её мы обсудим чуть позже), позволяющую копировать содержимое на верхний слой, доступный для записи, где такое содержимое может быть безопасно изменено.
Однако технологию объединённого монтирования (или объединённой файловой системы), по сути, нельзя считать отдельным типом файловой системы. Это, скорее, особая концепция с множеством реализаций. Некоторые реализации работают быстрее, некоторые медленнее, некоторые проще в использовании, некоторые сложнее — проще говоря, у разных реализаций разные цели и разные уровни зрелости. Мы поговорим про OverlayFS, сейчас она и используется в Docker

### OverlayFS
OverlayFS — это объединяющая файловая система для Linux, позволяющая накладывать одно дерево каталогов (обычно доступное для записи) на другое, доступное только для чтения. Это обеспечивает объединённый вид файловой системы, где изменения записываются в верхний слой, не изменяя нижний.

**Основные компоненты OverlayFS:**

- **Нижняя файловая система (lower)**: Обычно доступна только для чтения и содержит исходные данные.
- **Верхняя файловая система (upper)**: Доступна для записи и хранит изменения, сделанные пользователем.
- **Рабочий каталог (workdir)**: Необходим для некоторых операций OverlayFS и должен находиться на том же файловом системе, что и верхний каталог.

**Принцип работы OverlayFS:**

1. **Объединение директорий**: При монтировании OverlayFS объединяет верхний и нижний каталоги в единое представление. Если объект (файл или директория) присутствует в обоих каталогах, приоритет отдаётся объекту из верхнего каталога.
    
2. **Обработка файлов**:
    
    - **Чтение**: Если файл существует в верхнем каталоге, он читается оттуда; иначе — из нижнего.
    - **Запись**: При попытке записи в файл из нижнего каталога происходит операция "копирования при записи" (copy-up): файл копируется в верхний каталог, и изменения применяются к этой копии.
3. **Удаление файлов и директорий**:
    
    - **Whiteout**: Для удаления файла из нижнего каталога OverlayFS создаёт специальный объект в верхнем каталоге, называемый whiteout. Это позволяет скрыть файл из нижнего каталога без его физического удаления.
    - **Непрозрачные директории (opaque directories)**: При удалении директории создаётся специальный атрибут, обозначающий её как непрозрачную, что предотвращает объединение содержимого с нижним каталогом.
**Как работает overlayFS:**
- **Слои образа:** При сборке образа из Dockerfile каждая инструкция, такая как RUN, COPY или ADD, создаёт новый слой. Эти слои хранятся как только для чтения и комбинируются с помощью overlayFS.
- **Механизм copy-on-write:** Когда контейнер запускается, добавляется верхний записываемый слой. Если файл из нижнего слоя (например, из базового образа) изменяется, он копируется в этот верхний слой (операция copy-up), и изменения применяются только там. Это позволяет нижним слоям оставаться неизменными, что экономит место и упрощает управление.
- **Хранение слоёв:** Слои хранятся в директории, например, /var/lib/docker/overlay2 на хосте Linux, где каждый слой идентифицируется уникальным хэшем. Это позволяет нескольким контейнерам делить одни и те же слои, снижая потребление дискового пространства.
**Преимущества OverlayFS:**
- **Эффективность**: Благодаря механизму "копирования при записи" уменьшается количество операций записи, что особенно полезно для систем с ограниченными ресурсами.
- **Гибкость**: Позволяет создавать изолированные среды, где изменения не затрагивают исходные данные, что полезно для тестирования и разработки.

**Ограничения OverlayFS:**

- **Переименование файлов**: Переименование файлов поддерживается ограниченно и может потребовать полного копирования файла в верхний каталог.
- **Слияние изменений**: OverlayFS не поддерживает автоматическое слияние изменений из верхнего каталога в нижний.

OverlayFS активно используется в системах, где требуется наложение файловых систем, например, в LiveCD или контейнерных технологиях, для обеспечения изоляции и управления изменениями.

Итак, у нас имеется образ (nginx), с которым можно работать, далее нужно проверить его слои. Проверить слои образа можно, либо запустив проверку образа в Docker и изучив поля GraphDriver, либо перейдя в каталог /var/lib/docker/overlay2(тут хранятся слои кстати), в котором хранятся все слои образа. Выполним обе эти операции и посмотрим, что получится
Если внимательно посмотреть на полученные результаты, можно заметить, что они весьма похожи на те, что мы уже наблюдали после применения команды mount, не находите?

- LowerDir: это каталог, в котором слои образа, доступные только для чтения, разделены двоеточиями.
    
- MergedDir: объединённое представление всех слоев образа и контейнера.
    
- UpperDir: слой для чтения и записи, на котором записываются изменения.
    
- WorkDir: рабочий каталог, используемый Linux OverlayFS для подготовки объединённого представления.

Ну давайте теперь мы запустим контейнер и изучим его слои.
Из представленных выше выходных данных следует, что те же каталоги, которые были перечислены в выводе команды docker inspect nginx ранее как MergedDir, UpperDir и WorkDir (с id 3d963d191b2101b3406348217f4257d7374aa4b4a73b4a6dd4ab0f365d38dfbd), теперь являются частью LowerDir контейнера. В нашем случае LowerDir составляется из всех слоев образа nginx, размещённых друг на друге. Поверх них размещается слой в UpperDir, доступный для записи, содержащий каталоги /etc, /run и /var. Также, раз уж мы выше упомянули MergedDir, можно видеть всю доступную для контейнера файловую систему, в том числе всё содержимое каталогов UpperDir и LowerDir.

---

## **Как Docker управляет сетью? 

### Основные темы:

✅ Типы сетей: **bridge, host, none, overlay**  
✅ Как контейнеры взаимодействуют между собой?  
✅ Что такое `docker0`?
#### Построение сетей между контейнерами

Docker предоставляет несколько режимов сетей, но по умолчанию используется мостовая сеть (bridge network), которая создаёт виртуальную сеть для контейнеров на одном хосте.

**Мостовая сеть (bridge network):**
Мостовая сеть обеспечивает взаимодействие подключенных к ней контейнеров. Соответственно, устройство Bridge перенаправляет трафик между сегментами сети. При этом, важной особенностью мостовой сети является то, что здесь обеспечивается изоляция от контейнеров, которые не подключены к данной мостовой сети. Тем самым мы получаем выделенную сеть, внутри которой контейнеры могут функционировать беспрепятственно, но которые защищены от взаимодействия с внешними контейнерами. Для того, чтобы находиться в одной мостовой сети, контейнеры должны выполняться на одном и том же хосте демона Docker.

- **Создание и подключение:** При запуске Docker автоматически создаёт интерфейс docker0, который действует как программный мост. Каждый контейнер, подключённый к этой сети, получает виртуальный сетевой интерфейс, связанный с docker0, и уникальный IP-адрес из частной подсети, например, 172.17.0.0/16, где docker0 имеет адрес шлюза, например, 172.17.0.1.
- **Коммуникация между контейнерами:** Контейнеры в одной мостовой сети могут общаться друг с другом, отправляя пакеты через docker0. Например, если контейнер A хочет отправить пакет контейнеру B, он отправляет его на docker0, который перенаправляет пакет на интерфейс контейнера B на основе IP-адреса.
- **Доступ к внешним сетям:** Для доступа к интернету или другим сетям контейнеры используют docker0 как шлюз, который перенаправляет трафик через сетевой интерфейс хоста. Для входящего трафика порты публикуются с помощью флага -p, например, -p 8080:80 мапит порт 8080 хоста на порт 80 контейнера.
- **Изоляция:** Контейнеры в разных мостовых сетях изолированы друг от друга, что обеспечивает безопасность.

**Другие режимы сетей:**

- **Host network:** Контейнер делит сетевой стек хоста, используя его IP-адрес и интерфейсы. Это повышает производительность, устраняя необходимость в NAT, но снижает изоляцию, что может быть рискованно для небезопасных приложений.
- **None network:** Контейнер не имеет сетевых интерфейсов, что полностью изолирует его от сети, полезно для изолированных задач.
- **Overlay network:** Используется для многохостовых сценариев, таких как Docker Swarm, позволяя контейнерам на разных хостах общаться, как если бы они были в одной сети. Это достигается с помощью распределённой сети, часто с использованием VXLAN.
- _macvlan_: сети Macvlan позволяют присваивать контейнеру MAC-адрес, благодаря чему он выглядит как физическое устройство в сети.
Предположим, у нас есть два контейнера, A и B, подключённых к одной мостовой сети. Если A отправляет пакет на IP-адрес B, пакет проходит через docker0, который перенаправляет его на интерфейс B. Для доступа к интернету A отправляет пакет на шлюз (IP docker0), и хост маршрутизирует его дальше. Для внешнего доступа к сервису в A нужно опубликовать порт, например, docker run -p 8080:80 -d nginx, чтобы внешние клиенты могли подключиться к порту 8080 хоста и попасть в контейнер.

---


## Docker Volumes :)

Docker Volumes — это механизм для управления постоянными данными в контейнерах, которые по умолчанию являются безсостояними, то есть данные, созданные внутри контейнера, теряются при его удалении. Volumes позволяют сохранять данные за пределами контейнера, обеспечивая их постоянство и возможность совместного использования между несколькими контейнерами. Это особенно полезно для таких случаев, как базы данных, журналы или конфигурационные файлы, где данные должны сохраняться между перезапусками или удалениями контейнеров.

Volumes управляются Docker и хранятся на хост-машине, что отличает их от слоя записи контейнера, который также хранится на хосте, но удаляется вместе с контейнером.

#### Типы томов и их различия

Существует несколько типов томов в Docker, каждый из которых имеет свои особенности:

- **Именованные тома (Named Volumes):** Это тома, которые вы создаёте и управляете явно, с указанием имени. Они хранятся в директории, управляемой Docker, например, /var/lib/docker/volumes/<имя_тома>/_data на Linux. Это делает их удобными для управления и совместного использования.
- **Анонимные тома (Anonymous Volumes):** Создаются автоматически Docker, когда вы используете том без указания имени. Они имеют сгенерированное имя и менее удобны для управления, так как их идентификация сложнее.
- **Привязанные монтировки (Bind Mounts):** Это тома, где вы указываете конкретную директорию на хост-машине, которая монтируется в контейнер. Директория должна существовать на хосте, и данные хранятся непосредственно в этой директории.

Различия между этими типами заключаются в уровне управления и абстракции. Именованные тома и анонимные тома управляются Docker, тогда как привязанные монтировки требуют ручного управления директорией на хосте.

#### Технические детали работы под капотом

Под капотом Docker Volumes используют системный вызов Linux mount для монтирования директории с хоста в файловую систему контейнера. Давайте разберём этот процесс шаг за шагом:

1. **Создание и хранение тома:**
    - При создании именованного тома, например, с помощью команды docker volume create my_volume, Docker создаёт директорию, например, /var/lib/docker/volumes/my_volume/_data, где будут храниться данные тома.
    - Для анонимных томов Docker также создаёт директорию, но с сгенерированным именем, что делает их менее удобными для управления.
    - Для привязанных монтировок вы указываете путь на хосте, например, /host/path, который должен существовать.
2. **Монтирование в контейнер:**
    - Когда вы запускаете контейнер с томом, например, с помощью docker run -v my_volume:/app/data -it alpine sh, Docker выполняет системный вызов mount, чтобы смонтировать директорию тома (например, /var/lib/docker/volumes/my_volume/_data) в указанный путь в контейнере (/app/data).
    - Этот процесс происходит в пространстве имен (namespace) контейнера, так что монтирование видно только внутри контейнера, но не влияет на хост напрямую, если не учитывать права доступа.
3. **Взаимодействие с файловой системой контейнера:**
    - Контейнеры имеют файловую систему, которая состоит из слоёв образа (только для чтения) и верхнего записываемого слоя. Когда вы монтируете том, он накладывается на часть файловой системы контейнера, заменяя то, что было там раньше.
    - Например, если в образе есть файлы в /app/data, после монтирования тома эти файлы будут скрыты, и контейнер будет видеть только файлы из тома. Это поведение аналогично тому, как работают монтировки в Linux.
    - Любые записи в смонтированный путь (/app/data в контейнере) фактически записываются в директорию тома на хосте, например, /var/lib/docker/volumes/my_volume/_data.
4. **Механизм постоянства и совместного использования:**
    - Поскольку данные хранятся на хосте, они сохраняются даже после удаления контейнера. Это отличает тома от слоя записи контейнера, который удаляется вместе с контейнером.
    - Несколько контейнеров могут быть смонтированы к одному и тому же тому, что позволяет обмениваться данными. Например, если контейнер A записывает файл в том, контейнер B, подключённый к тому же тому, сможет прочитать этот файл.
5. **Производительность и особенности:**
    - Исследования показывают, что тома могут обеспечивать лучшую производительность для операций записи по сравнению со слоем записи контейнера, так как они представляют собой прямой доступ к файловой системе хоста, без накладных расходов объединённой файловой системы (Union Filesystem), такой как overlayFS.
    - Однако для приложений с интенсивной записью, таких как базы данных, рекомендуется использовать тома, чтобы избежать замедлений, связанных с копированием при записи (copy-on-write) в слое записи контейнера.

#### Жизненный цикл и управление томами

- Томы существуют до тех пор, пока их явно не удалить, например, с помощью команды docker volume rm my_volume.
- Даже если все контейнеры, использующие том, удалены, том остаётся и может быть использован другими контейнерами в будущем.
- Это делает тома удобными для разделения забот, например, хранения данных отдельно от кода приложения. Например, вы можете обновить образ приложения, не затрагивая данные в томе.

#### Права доступа и разрешения

Важным аспектом является управление правами доступа. Поскольку контейнер может запускаться от имени определённого пользователя (например, с флагом `--user`), а директория тома на хосте имеет свои права, могут возникнуть проблемы с владением и доступом.

- Например, если контейнер запускается от пользователя с ID 1001, а директория тома принадлежит root на хосте, контейнер может не иметь прав на запись.
- Чтобы решить это, можно использовать флаг --user для указания пользователя внутри контейнера или настроить права доступа к директории тома на хосте.
#### Примеры использования и команд

Чтобы лучше понять, как это работает, рассмотрим примеры:

- **Создание и использование именованного тома:**
```
docker volume create my_volume  
docker run -v my_volume:/app/data -it alpine sh  
```
Внутри контейнера, если вы создадите файл в /app/data, он будет сохранён в /var/lib/docker/volumes/my_volume/_data на хосте и сохранится после удаления контейнера.

- **Привязанная монтировка:**
```
docker run -v /host/path:/app/data -it alpine sh
```
Здесь /host/path на хосте монтируется в /app/data в контейнере, и данные хранятся непосредственно в /host/path.

- **Анонимный том**:
```
docker run -v /app/data -it alpine sh  
```
Docker создаст анонимный том с сгенерированным именем, и данные будут храниться в соответствующей директории, управляемой Docker.


## Полезняшки

слайд с куарподиком, где ссылка на гугл докс с всякими интересностями про докер :)